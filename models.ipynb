{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"*Import libraries (tensorflow backend)*"},{"metadata":{"trusted":true,"_uuid":"7e5a5d2707651204c12b7b985005e4c07c8e3cdf"},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D,ZeroPadding2D,Convolution2D,Dropout,BatchNormalization\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.optimizers import SGD\nfrom keras import optimizers\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, AveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras.applications.resnet50 import preprocess_input\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057f59b843d09d8b756244302518de928fb9c574"},"cell_type":"code","source":"img_width, img_height = 224, 224\ntrain_data = '../input/chest_xray/chest_xray/train'\ntest_data = '../input/chest_xray/chest_xray/test'\nval_data = '../input/chest_xray/chest_xray/val'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa69460a019c89d6b960a81cf9146090fcf0a090"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\nval_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical')\n\nvalidation_generator = val_datagen.flow_from_directory(\n    val_data,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical')\ninput_shape=(224, 224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60b4844fd42b597220c30736bb8d9ca961da3d18"},"cell_type":"code","source":"# input_shape = (224, 224, 3)\n# training_set = train_datagen.flow_from_directory('../input/chest_xray/chest_xray/train',\n#                                                  target_size = (224,224),\n#                                                  batch_size = 32,\n#                                                  class_mode = 'categorical')\n# val_set = val_datagen.flow_from_directory('../input/chest_xray/chest_xray/val',\n#                                             target_size = (224,224),\n#                                             batch_size = 32,\n#                                             class_mode = 'categorical')\n# test_set = test_datagen.flow_from_directory('../input/chest_xray/chest_xray/test',\n#                                             target_size = (224,224),\n#                                             batch_size = 32,\n#                                             class_mode = 'categorical')\n# input_shape = (224, 224, 3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d04173fb166d7fa34e7ed0bca04cafe1cb2009f9"},"cell_type":"markdown","source":"# MODEL-1:Simple CNN\n"},{"metadata":{"trusted":true,"_uuid":"5ed6c2c4c2b18d12169a6fc7fe8bbd26ff518f71"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(activation = 'relu', units = 128))\nmodel.add(Dense(activation = 'sigmoid', units = 2))\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4da0cba74111d65aef1e92595d25c05c78d0a8dd"},"cell_type":"markdown","source":"****Convolution**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Choose 32 feature detectors and an input shape of 3D image of 64x64 pixels"},{"metadata":{"_uuid":"4ce768ba33f2f5590a6bd4c493b9af8ef3d157bb"},"cell_type":"markdown","source":"***Pooling***"},{"metadata":{"_uuid":"b14dcd4c6381afd0aaed7cb29e66b27324532636"},"cell_type":"markdown","source":"Pooling is made with a 2x2 array "},{"metadata":{"_uuid":"04b63d2ca0d4ddafa0a60104b7b88327044c1a16"},"cell_type":"markdown","source":"Add 2nd convolutional layer with the same structure as the 1st to improve predictions"},{"metadata":{"_uuid":"ef4f6a1aa4ace2bd1a1b3c8799d007ff84dadde5"},"cell_type":"markdown","source":"***Flattening***"},{"metadata":{"_uuid":"1e0a776799365308f1f2befa25f62a9e3c50e4fd"},"cell_type":"markdown","source":"***Full Connection***"},{"metadata":{"_uuid":"b6bdaac45213b951b9d0d165c531bc550dccb1d4"},"cell_type":"markdown","source":"CNN has 128 nodes in the first layer of the ANN that's connected in the backbone with rectifier activation function.  We then add sigmoid activation function because we have binary outcome with 1 node in the output layer."},{"metadata":{"_uuid":"694426ce4dccac8b432323f831c6f77271b80801"},"cell_type":"markdown","source":"***Compile the CNN***"},{"metadata":{"_uuid":"b22971015a623f46be706ebdaecf3aa6dd9c2671"},"cell_type":"markdown","source":"adam is for stohastic gradient descent and binary crossentropy for logarithmic loss for binary outcomes"},{"metadata":{"_uuid":"81a6b69281f699afe31f472facc14e35488af0f6"},"cell_type":"markdown","source":"***Image Augmentation***"},{"metadata":{"_uuid":"632978357335d52510e471e74260b4ccb9e1efed"},"cell_type":"markdown","source":"Apply several transformations to train the model in a better significant way, keras documentation provides all the required information for augmentation"},{"metadata":{"_uuid":"c96af2c7eaece4843d411739a6b82c17fe047f8c"},"cell_type":"markdown","source":"Target size is 64x64. This is the size of the images the model is trained above and size of the batches in which random samples of our images will be included. Class mode is binary because dependent variable is binary."},{"metadata":{"_uuid":"494f36581178f0bafc8521d45fcf09e45a6c5d97"},"cell_type":"markdown","source":"# MODEL-2:Modified CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize model\nmodel = Sequential()\n\n#CNN Layer 1\n#input: 28X28 images with 1 channel -> (28X28X1) tensors.\n#this applies 64 convolution filters of size 3X3 each.\nmodel.add(ZeroPadding2D((1,1), input_shape=input_shape))\nmodel.add(Convolution2D(filters=64, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(Dropout(0.4))\n\n#CNN Layer 2\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(filters=64, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\n\n#Flatten the output before feeding these to the fully connected Neurons                                    \nmodel.add(Flatten())\n\n#Fully connected Layers\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='sigmoid', kernel_initializer='he_normal'))\n\nprint(model.summary())\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL-3:RESNET50"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import ResNet50 with pre-trained weights. do not include fully #connected layers\nbase_model = ResNet50(weights='imagenet', include_top=False)\n# result = model.output\n# result = GlobalAveragePooling2D()(result)\n# # add a fully-connected layer\n# result = Dense(512, activation='relu')(result)\n# # and a fully connected output/classification layer\n# predictions = Dense(2, activation='sigmoid')(result)\n# model_resnet = Model(inputs=model.input, outputs=predictions)\n# base_model=ResNet50(include_top=False, weights='imagenet',input_shape=input_shape)\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\n#Fully connected Layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))                            \nmodel.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL-4:InceptionV3"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import applications\n\nbase_model=applications.InceptionV3(include_top=False, weights='imagenet')\n# result = model.output\n# result = GlobalAveragePooling2D()(result)\n# # add a fully-connected layer\n# result = Dense(512, activation='relu')(result)\n# # and a fully connected output/classification layer\n# predictions = Dense(2, activation='sigmoid')(result)\n# model_incep = Model(inputs=model.input, outputs=predictions)\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\n#Fully connected Layers\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))                            \nmodel.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              epochs=16,\n                              shuffle=True,\n                              validation_data=validation_generator, \n                              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy and Loss Graphs for training and validation-"},{"metadata":{"trusted":true,"_uuid":"d15c1cbae90bac4af6158637a440b4b6a58af871"},"cell_type":"code","source":"#Accuracy\nprint(history.history.keys())\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()\n\n#Loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation-"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator)\nprint('acc =',scores[1]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores[0],scores[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}